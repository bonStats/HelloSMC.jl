{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Lotka-Volterra Markov Jump Process \n",
    "\n",
    "This notebook will demonstrate how to use SequentialMonteCarlo.jl for a Hidden Markov Model with Lotka-Volterra Markov Jump Process dynamics.\n",
    "\n",
    "First we load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SequentialMonteCarlo\n",
    "using Distributions\n",
    "using Catalyst\n",
    "using JumpProcesses\n",
    "using Statistics\n",
    "using Plots\n",
    "using StatsPlots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load in the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 1.0:1.0:50.0\n",
    "n = 50\n",
    "y = [25 54 70 106 155 187 153 104 54 23 15 6 4 7 11 18 26 22 37 43 55 114 190 203 201 97 46 21 29 6 10 13 10 13 18 20 23 40 66 81 119 157 196 227 154 61 24 20 10 11;\n",
    "    59 45 50 48 89 113 203 378 422 350 288 228 150 124 118 101 67 54 63 48 49 41 82 130 270 435 450 366 280 263 213 159 100 89 71 50 33 45 45 23 45 59 110 223 479 435 406 322 246 201]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SequentialMonteCarlo.jl is a flexible package for designing SMC algorithms. It has three major components:\n",
    "- Particle structure\n",
    "- Mutation function (includes initial distribution)\n",
    "- Potential function (log-scale)\n",
    "\n",
    "The first step is to define the type of particle the algorithm will manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct LVParticle\n",
    "    prey::Int64\n",
    "    pred::Int64\n",
    "    LVParticle() = new() # initialise empty\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define the mutation function, we need to define how the Markov Process Jump evolves. \n",
    "\n",
    "In julia we can use JumpProcesses.jl to simulate integer-valued Markov Jump Processes. One way to do this is with the Catalyst.jl reaction network syntax.\n",
    "\n",
    "The Lotka-Volterra model has a chemical reaction network \n",
    "\\begin{align*}\n",
    "X_1 & \\overset{c_1}{\\rightarrow} 2X_1\\\\\n",
    "X_1 + X_2 & \\overset{c_2}{\\rightarrow} 2X_2\\\\\n",
    "X_2 & \\overset{c_3}{\\rightarrow} \\emptyset\n",
    "\\end{align*}\n",
    "\n",
    "which can be written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lveqns = @reaction_network begin\n",
    "    c1, prey --> 2*prey         # prey reproduction\n",
    "    c2, prey + pred --> 2*pred  # prey death, pred reproduction\n",
    "    c3, pred --> 0              # pred death\n",
    "end\n",
    "\n",
    "rates = (:c1 => 0.5, :c2 => 0.0025, :c3 => 0.3)\n",
    "initial = [71, 79] # latent at time 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above specification, we can define a mutation kernel for SequentialMonteCarlo.jl to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutation kernel\n",
    "function M!(newParticle::LVParticle, rng, t::Int64, oldParticle::LVParticle, ::Nothing)\n",
    "    if t == 1\n",
    "        u0 = initial\n",
    "        tspan = (0.0, ts[1])\n",
    "    else\n",
    "        u0 = [oldParticle.prey, oldParticle.pred]\n",
    "        tspan = (ts[t-1], ts[t])\n",
    "    end\n",
    "    \n",
    "    dprobt = DiscreteProblem(lveqns, u0, tspan, rates)\n",
    "    jprobt = JumpProblem(lveqns, dprobt, Direct(), rng = rng)\n",
    "    res = solve(jprobt, SSAStepper())\n",
    "\n",
    "    newParticle.prey = res(ts[t])[1]\n",
    "    newParticle.pred = res(ts[t])[2]\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last we have the potential function (likelihood) for which we assume \n",
    "\\begin{align}\n",
    "Y_1 &\\sim \\text{Poisson}(0.5X_1)\\\\\n",
    "Y_2 &\\sim \\text{Poisson}(0.8X_2)\n",
    "\\end{align}\n",
    "which defines our log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lG(t::Int64, particle::LVParticle, ::Nothing)\n",
    "    preydist = Poisson(0.5*particle.prey)\n",
    "    preddist = Poisson(0.8*particle.pred)\n",
    "    return logpdf(preydist, y[1,t]) + logpdf(preddist, y[2,t])\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the SMC algorithm we need to specify the number of particles $N$, number of threads, the resampling threshold in terms of the relative ESS, and whether to save all the output (instead of just the terminal particles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2^10\n",
    "threads = 1\n",
    "κ = 0.5 # relative ESS threshold\n",
    "saveall = true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete SMC model can be specified by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMCModel(M!, lG, n, LVParticle, Nothing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we make a location to save the output from running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smcio = SMCIO{model.particle, model.pScratch}(N, n, threads, saveall, κ)\n",
    "smcio.N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run the model using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc!(model, smcio) # overwrites smcio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot some path realisations (predictive) as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load true latent states\n",
    "x = readdlm(\"prey_pred_true_latent.csv\", ',', Int64)\n",
    "\n",
    "plot(y[1,:], label=\"obs\", title = \"Prey estimated latent states vs observations\")\n",
    "pids = sample(1:smcio.N, 100)\n",
    "for i in pids\n",
    "    anc = getindex.(smcio.allEves, i)\n",
    "    u = getindex.(smcio.allZetas, reverse(anc))\n",
    "    plot!(getfield.(u, :prey), color = \"grey\", alpha = 0.5, label = \"\")\n",
    "end\n",
    "plot!(x[1,:], label=\"latent\", color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(y[2,:], label=\"obs\", title = \"Pred. estimated latent states vs observations\")\n",
    "pids = sample(1:smcio.N, 100)\n",
    "for i in pids\n",
    "    anc = getindex.(smcio.allEves, i)\n",
    "    u = getindex.(smcio.allZetas, reverse(anc))\n",
    "    plot!(getfield.(u, :pred), color = \"grey\", alpha = 0.5, label = \"\")\n",
    "end\n",
    "plot!(x[2,:], label=\"latent\", color = \"red\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Plot the $t=5$ marginal predictive and updated distributions of the particles and compare. Hint: consider using `density(..., weights = Weights(...))`.\n",
    "\n",
    "2. Change the adaptive resampling threshold $\\kappa$ and rerun the algorithm. Does your chosen value of $\\kappa$ result in a better particle filter? Justify why or why not with summaries from the particle filter.\n",
    "\n",
    "3. Change the parameters of the model $c_1,c_2,c_3$ slightly and rerun the particle filter. Can you determine how sensitive the particle filter is to the choice of parameters? Does it perform better or worse with your choice? What might be some reasons for this?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
